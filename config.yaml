# AI MCP Server Configuration

# Gemini API Configuration
gemini:
  api_key: "your_api_key_here"  # Replace with your actual Gemini API key
  model: "gemini-2.0-flash"           # Default model to use
  max_tokens: 2048             # Maximum tokens per response

# Server Configuration
server:
  host: "0.0.0.0"             # Server host
  port: 8888                   # Server port
  timeout: 30                  # Request timeout in seconds

# Logging Configuration
logging:
  level: "info"               # Log level (debug, info, warn, error)
  format: "text"              # Log format (text, json)
  output: "stdout"            # Log output (stdout, file) 